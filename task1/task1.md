# Task 1

## 随机森林算法梳理
1. 集成学习的概念 \
    集成学习（ensemble learning）是指通过构建并组合多个学习期来完成学习任务，集成学习将多个学习器进行结合，可以获得比个体的学习器更加显著的泛化能力，通过[随机有放回采样]方式获得多个数据子集进行多个学习器的训练，

2. 个体学习器的概念 \
     个体学习器通常是由单一的算法在一组数据上学习得到的，也被称为基学习器，一般在bagging和boosting中使用得到，一般为决策树（ID3、C4.5、CART）等不稳定的学习器

3. boosting 和 bagging的概念、异同点 
    * boosting的概念：boosting的基学习器采用按序进行训练，所有基学习器的训练数据都是一样的，最主要的改变是每训练出一个基学习器，就要相应的修改每一个样本在该数据中权重，以及赋予每一个基学习器的可信权重，是一个加法模型得到的强学习器，最后结合所有基学习器的结果

    * bagging的概念：bagging是对所有数据进行随机有放回的抽样出多个子训练集，每一个子训练集进行对应的基学习器的训练，得到多个基学习器，最后结合每一个基学习器的结果进行预测

    * 异同点： \
    a) 采用的训练数据不同，bagging是在原始数据集中有放回的随机抽样，而boosting的训练数据是一样的，但每个样本在学习器中的权重会随着上一个学习器的学习结果发生变化 \
    b) bagging可以并行训练；boosting只能按序，前向分步算法 \
    c) Bagging \
    d)

4. 理解不同的结合策略（平均法、投票法、学习法）

5. 随机森林的思想

6. 随机森林的推广

7. 随机森林的优缺点

8. 随机森林在sklearn中的参数解释

9. 随机森林的应用场景

参考资料: \
    西瓜书 \
    cs229吴恩达机器学习课程 \
    李航统计学习 \
    谷歌搜索 \
    公式推导参考：http://t.cn/EJ4F9Q0